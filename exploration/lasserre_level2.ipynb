{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b1c2d3",
   "metadata": {},
   "source": [
    "# Level-2 Lasserre (Moment/SOS) SDP for Discretized $C_{1a}$\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook implements and evaluates the **level-2 Lasserre (moment/SOS) SDP relaxation**\n",
    "for the discretized Sidon autocorrelation constant $C_{1a}$. The Shor (level-1) relaxation\n",
    "gives a useless bound of $2P/(2P-1) \\to 1$. Level 2 constrains fourth-order moments via a\n",
    "larger moment matrix $M_2$, preventing the uniform anti-diagonal spreading that defeated Shor.\n",
    "\n",
    "The key challenge is that the epigraph constraints $\\eta \\geq p_k(x)$ must be enforced via\n",
    "**localizing matrices** $M_1((\\eta - p_k) \\cdot \\mu) \\succeq 0$, not mere scalar\n",
    "inequalities. Since $\\eta$ appears bilinearly with the moment variables, we use **binary\n",
    "search on $\\eta$**, solving an SDP feasibility problem at each step.\n",
    "\n",
    "## Results\n",
    "\n",
    "| P | Lasserre-2 LB | Shor LB | Primal UB | Gap Closed |\n",
    "|---|---------------|---------|-----------|------------|\n",
    "| 2 | 1.777766 | 1.333333 | 1.777778 | 100.0% |\n",
    "| 3 | 1.704102 | 1.200000 | 1.706667 | 99.5% |\n",
    "| 4 | 1.644180 | 1.142857 | 1.644466 | 99.9% |\n",
    "| 5 | 1.342916 | 1.111111 | 1.651197 | 42.9% |\n",
    "| 6 | 1.281007 | 1.090909 | 1.601723 | 37.2% |\n",
    "\n",
    "The relaxation is **nearly tight for $P \\leq 4$** (closing >99% of the Shor-to-primal gap)\n",
    "but degrades significantly at $P \\geq 5$, likely due to solver numerics and the rapidly\n",
    "growing SDP size. The moment matrix rank grows with $P$, indicating the relaxation is not\n",
    "converging to a rank-1 (exact) solution at larger sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e56446",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The Shor (level-1) SDP gives bound $2P/(2P-1) \\to 1$, which is useless.\n",
    "Level 2 constrains fourth-order moments via a larger moment matrix $M_2$,\n",
    "preventing the uniform anti-diagonal spreading that defeated Shor.\n",
    "\n",
    "**Key idea:** $M_2$ is indexed by monomials of degree $\\leq 2$. Entry $(\\alpha,\\beta) = E[x^{\\alpha+\\beta}]$.\n",
    "Moment consistency + PSD + localizing matrices for $x_i \\geq 0$ **and** $\\eta - p_k(x) \\geq 0$ give a much tighter relaxation.\n",
    "\n",
    "**Formulation note:** The constraints $\\eta \\geq p_k(x)$ must be enforced via\n",
    "localizing matrices $M_1((\\eta - p_k) \\cdot \\mu) \\succeq 0$, not mere scalar\n",
    "inequalities $\\eta \\geq \\mathbb{E}[p_k]$. The scalar version collapses to Shor.\n",
    "Since $\\eta$ appears bilinearly with the moment variables, we use binary search on $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 1: Imports.\"\"\"\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "import time\n",
    "\n",
    "print(f\"cvxpy version: {cp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 1b: Inline utilities (StepFunction & peak_autoconv_exact).\n",
    "\n",
    "These were previously imported from src.representations and src.convolution.\n",
    "Defined inline here so the notebook is self-contained.\n",
    "\"\"\"\n",
    "\n",
    "class StepFunction:\n",
    "    \"\"\"A piecewise-constant function on [-1/4, 1/4] defined by bin edges and heights.\n",
    "    \n",
    "    Attributes:\n",
    "        edges: array of shape (N+1,) -- bin boundaries (ascending).\n",
    "        heights: array of shape (N,) -- function value on each bin.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, edges, heights):\n",
    "        self.edges = np.asarray(edges, dtype=float)\n",
    "        self.heights = np.asarray(heights, dtype=float)\n",
    "\n",
    "    @classmethod\n",
    "    def from_heights(cls, edges, heights):\n",
    "        return cls(edges=edges, heights=heights)\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        \"\"\"Evaluate the step function at an array of points x.\"\"\"\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        result = np.zeros_like(x)\n",
    "        for k in range(len(self.heights)):\n",
    "            mask = (x >= self.edges[k]) & (x < self.edges[k + 1])\n",
    "            result[mask] = self.heights[k]\n",
    "        return result\n",
    "\n",
    "\n",
    "def _autoconv_direct(sf, t_values):\n",
    "    \"\"\"Compute autoconvolution (f*f)(t) at given t values by direct integration.\"\"\"\n",
    "    t_values = np.asarray(t_values, dtype=float)\n",
    "    edges = sf.edges\n",
    "    h = sf.heights\n",
    "    N = len(h)\n",
    "    a = edges[:-1]\n",
    "    b = edges[1:]\n",
    "    hh = h[:, None] * h[None, :]  # (N, N)\n",
    "    T = len(t_values)\n",
    "    result = np.empty(T, dtype=float)\n",
    "    batch_size = 1000\n",
    "    for start in range(0, T, batch_size):\n",
    "        end = min(start + batch_size, T)\n",
    "        t_batch = t_values[start:end]\n",
    "        lo = np.maximum(a[:, None, None], t_batch[None, None, :] - b[None, :, None])\n",
    "        hi = np.minimum(b[:, None, None], t_batch[None, None, :] - a[None, :, None])\n",
    "        overlap = np.maximum(0.0, hi - lo)\n",
    "        result[start:end] = (hh[:, :, None] * overlap).sum(axis=(0, 1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def peak_autoconv_exact(sf):\n",
    "    \"\"\"Compute the exact peak of the autoconvolution by evaluating at all\n",
    "    breakpoints (where the piecewise-linear (f*f)(t) can attain its max).\"\"\"\n",
    "    edges = sf.edges\n",
    "    bp = (edges[:, None] + edges[None, :]).ravel()\n",
    "    bp = np.unique(bp)\n",
    "    bp = bp[(bp >= -0.5) & (bp <= 0.5)]\n",
    "    conv = _autoconv_direct(sf, bp)\n",
    "    return float(np.max(conv))\n",
    "\n",
    "\n",
    "# Quick smoke test\n",
    "_edges = np.linspace(-0.25, 0.25, 5)\n",
    "_sf = StepFunction(edges=_edges, heights=np.ones(4) * 2.0)\n",
    "print(f\"Smoke test peak_autoconv_exact (uniform f=2): {peak_autoconv_exact(_sf):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56656d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 2: Monomial basis helpers.\"\"\"\n",
    "\n",
    "def monomial_basis(P, max_deg):\n",
    "    \"\"\"Enumerate monomials of degree <= max_deg in P variables.\n",
    "    Each monomial is a sorted tuple of variable indices.\n",
    "    E.g. x_0^2 x_1 -> (0, 0, 1).  Constant -> ().\n",
    "    \"\"\"\n",
    "    basis = [()]\n",
    "    for deg in range(1, max_deg + 1):\n",
    "        for combo in combinations_with_replacement(range(P), deg):\n",
    "            basis.append(combo)\n",
    "    return basis\n",
    "\n",
    "\n",
    "def combine(*multi_indices):\n",
    "    \"\"\"Combine multi-indices by concatenation and sorting.\"\"\"\n",
    "    return tuple(sorted(sum(multi_indices, ())))\n",
    "\n",
    "\n",
    "# Sanity checks\n",
    "print(\"P=2, deg<=2:\", monomial_basis(2, 2))\n",
    "print(\"combine((0,), (1,)):\", combine((0,), (1,)))\n",
    "print(\"combine((0,0), (1,)):\", combine((0,0), (1,)))\n",
    "print(\"combine((0,), (0,)):\", combine((0,), (0,)))\n",
    "\n",
    "# Check sizes\n",
    "for P in range(2, 7):\n",
    "    d = 1 + P + P*(P+1)//2\n",
    "    print(f\"P={P}: d={d}, M is {d}x{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 3: Level-2 Lasserre SDP solver with proper localizing matrices.\"\"\"\n",
    "\n",
    "def solve_lasserre_2(P, solver=None, verbose=False, eta_tol=1e-6):\n",
    "    \"\"\"Level-2 Lasserre SDP relaxation for discretized C_1a.\n",
    "    \n",
    "    The epigraph constraints \\u03b7 - p_k(x) \\u2265 0 are enforced via localizing\n",
    "    matrices M_1((\\u03b7 - p_k) \\u00b7 \\u03bc) \\u2265 0, not scalar inequalities \\u03b7 \\u2265 E[p_k].\n",
    "    Since this creates a bilinear dependence on (\\u03b7, y), we binary search on \\u03b7,\n",
    "    solving an SDP feasibility problem at each step.\n",
    "    \n",
    "    Returns dict with 'bound', 'first_moments', 'Y', 'M', 'M_rank', etc.\n",
    "    \"\"\"\n",
    "    # -- Bases --\n",
    "    basis_2 = monomial_basis(P, 2)   # for M_2\n",
    "    d = len(basis_2)                 # 1 + P + P(P+1)/2\n",
    "    basis_1 = monomial_basis(P, 1)   # for localizing matrices\n",
    "    loc_d = len(basis_1)             # 1 + P\n",
    "    all_beta = monomial_basis(P, 3)  # for simplex equality constraints\n",
    "    \n",
    "    # -- Collect all unique moments needed (degree <= 4) --\n",
    "    moments_set = set()\n",
    "    # From M_2\n",
    "    for i in range(d):\n",
    "        for j in range(i, d):\n",
    "            moments_set.add(combine(basis_2[i], basis_2[j]))\n",
    "    # From localizing matrices for x_k >= 0\n",
    "    for k in range(P):\n",
    "        for a in range(loc_d):\n",
    "            for b in range(a, loc_d):\n",
    "                moments_set.add(combine((k,), basis_1[a], basis_1[b]))\n",
    "    # From simplex equality constraints\n",
    "    for beta in all_beta:\n",
    "        moments_set.add(beta)\n",
    "        for i in range(P):\n",
    "            moments_set.add(combine((i,), beta))\n",
    "    # From localizing matrices for \\u03b7 - p_k(x) >= 0\n",
    "    for k_conv in range(2 * P - 1):\n",
    "        for a in range(loc_d):\n",
    "            for b in range(a, loc_d):\n",
    "                moments_set.add(combine(basis_1[a], basis_1[b]))\n",
    "                for i in range(P):\n",
    "                    j_val = k_conv - i\n",
    "                    if 0 <= j_val < P:\n",
    "                        moments_set.add(combine(basis_1[a], basis_1[b], (i,), (j_val,)))\n",
    "    \n",
    "    moments_list = sorted(moments_set, key=lambda m: (len(m), m))\n",
    "    moment_idx = {m: idx for idx, m in enumerate(moments_list)}\n",
    "    n_mom = len(moments_list)\n",
    "    print(f\"  P={P}: d={d}, loc_d={loc_d}, n_moments={n_mom}\")\n",
    "    \n",
    "    # -- Pre-compute indicator matrices (independent of \\u03b7) --\n",
    "    \n",
    "    # M_2 indicator matrices\n",
    "    B_M = {}\n",
    "    for i in range(d):\n",
    "        for j in range(i, d):\n",
    "            mu = combine(basis_2[i], basis_2[j])\n",
    "            idx = moment_idx[mu]\n",
    "            if idx not in B_M:\n",
    "                B_M[idx] = np.zeros((d, d))\n",
    "            B_M[idx][i, j] = 1\n",
    "            if i != j:\n",
    "                B_M[idx][j, i] = 1\n",
    "    \n",
    "    # x_k >= 0 localizing indicator matrices\n",
    "    B_Locs = []\n",
    "    for k in range(P):\n",
    "        B_L = {}\n",
    "        for a in range(loc_d):\n",
    "            for b in range(a, loc_d):\n",
    "                mu = combine((k,), basis_1[a], basis_1[b])\n",
    "                idx = moment_idx[mu]\n",
    "                if idx not in B_L:\n",
    "                    B_L[idx] = np.zeros((loc_d, loc_d))\n",
    "                B_L[idx][a, b] = 1\n",
    "                if a != b:\n",
    "                    B_L[idx][b, a] = 1\n",
    "        B_Locs.append(B_L)\n",
    "    \n",
    "    # Simplex equality constraint index data\n",
    "    simplex_data = []\n",
    "    for beta in all_beta:\n",
    "        lhs_indices = [moment_idx[combine((i,), beta)] for i in range(P)]\n",
    "        rhs_idx = moment_idx[beta]\n",
    "        simplex_data.append((lhs_indices, rhs_idx))\n",
    "    \n",
    "    # M_1 indicator matrices (\\u03b7 coefficient in localizing matrices)\n",
    "    B_M1 = {}\n",
    "    for a in range(loc_d):\n",
    "        for b in range(a, loc_d):\n",
    "            mu = combine(basis_1[a], basis_1[b])\n",
    "            idx = moment_idx[mu]\n",
    "            if idx not in B_M1:\n",
    "                B_M1[idx] = np.zeros((loc_d, loc_d))\n",
    "            B_M1[idx][a, b] = 1\n",
    "            if a != b:\n",
    "                B_M1[idx][b, a] = 1\n",
    "    \n",
    "    # p_k indicator matrices for each anti-diagonal k\n",
    "    B_pks = []\n",
    "    for k_conv in range(2 * P - 1):\n",
    "        B_pk = {}\n",
    "        for a in range(loc_d):\n",
    "            for b in range(a, loc_d):\n",
    "                for i in range(P):\n",
    "                    j_val = k_conv - i\n",
    "                    if 0 <= j_val < P:\n",
    "                        mu = combine(basis_1[a], basis_1[b], (i,), (j_val,))\n",
    "                        idx = moment_idx[mu]\n",
    "                        if idx not in B_pk:\n",
    "                            B_pk[idx] = np.zeros((loc_d, loc_d))\n",
    "                        B_pk[idx][a, b] += 1\n",
    "                        if a != b:\n",
    "                            B_pk[idx][b, a] += 1\n",
    "        B_pks.append(B_pk)\n",
    "    \n",
    "    # -- Build CVXPY problem with \\u03b7 as a Parameter --\n",
    "    y = cp.Variable(n_mom)\n",
    "    eta_param = cp.Parameter(nonneg=True)\n",
    "    constraints = []\n",
    "    \n",
    "    # M_2 >> 0\n",
    "    M_expr = sum(y[idx] * mat for idx, mat in B_M.items())\n",
    "    constraints.append(M_expr >> 0)\n",
    "    constraints.append(y[moment_idx[()]] == 1)\n",
    "    \n",
    "    # Localizing matrices for x_k >= 0\n",
    "    for B_L in B_Locs:\n",
    "        L_k = sum(y[idx] * mat for idx, mat in B_L.items())\n",
    "        constraints.append(L_k >> 0)\n",
    "    \n",
    "    # Simplex equality constraints: E[(sum x_i) * x^beta] = E[x^beta]\n",
    "    for lhs_indices, rhs_idx in simplex_data:\n",
    "        constraints.append(sum(y[i] for i in lhs_indices) == y[rhs_idx])\n",
    "    \n",
    "    # Localizing matrices for \\u03b7 - p_k(x) >= 0\n",
    "    # L_gk[a,b] = \\u03b7 * y_{\\u03b1_a+\\u03b1_b} - 2P * sum_{i+j=k} y_{\\u03b1_a+\\u03b1_b+e_i+e_j}\n",
    "    # This is affine in y for fixed \\u03b7 (eta_param).\n",
    "    M1_expr = sum(y[idx] * mat for idx, mat in B_M1.items())\n",
    "    for B_pk in B_pks:\n",
    "        pk_expr = sum(y[idx] * mat for idx, mat in B_pk.items())\n",
    "        L_gk = eta_param * M1_expr - 2 * P * pk_expr\n",
    "        constraints.append(L_gk >> 0)\n",
    "    \n",
    "    prob = cp.Problem(cp.Minimize(0), constraints)\n",
    "    \n",
    "    # -- Choose solver --\n",
    "    solver_list = ['CLARABEL', 'SCS'] if solver is None else [solver]\n",
    "    \n",
    "    def try_solve():\n",
    "        for s in solver_list:\n",
    "            try:\n",
    "                kwargs = {'verbose': False}\n",
    "                if s == 'SCS':\n",
    "                    kwargs.update({'max_iters': 10000, 'eps': 1e-7})\n",
    "                prob.solve(solver=s, warm_start=True, **kwargs)\n",
    "                return s, prob.status\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                raise\n",
    "            except BaseException:\n",
    "                # CLARABEL can raise pyo3_runtime.PanicException (a\n",
    "                # BaseException, not Exception) on some problem instances.\n",
    "                # Fall through to next solver.\n",
    "                continue\n",
    "        return None, 'solver_error'\n",
    "    \n",
    "    # -- Binary search on \\u03b7 --\n",
    "    eta_lo, eta_hi = 1.0, 2.0\n",
    "    t0 = time.time()\n",
    "    best_y = None\n",
    "    used_solver = None\n",
    "    n_iter = 0\n",
    "    \n",
    "    # Verify upper bound is feasible\n",
    "    eta_param.value = eta_hi\n",
    "    used_solver, status = try_solve()\n",
    "    if status not in ('optimal', 'optimal_inaccurate'):\n",
    "        eta_hi = 2.0 * P\n",
    "        eta_param.value = eta_hi\n",
    "        used_solver, status = try_solve()\n",
    "        if status not in ('optimal', 'optimal_inaccurate'):\n",
    "            print(f\"  WARNING: even eta={eta_hi} is infeasible ({status})\")\n",
    "            return {'status': 'infeasible', 'bound': None, 'time': time.time() - t0}\n",
    "    best_y = y.value.copy()\n",
    "    \n",
    "    # Main binary search loop\n",
    "    while eta_hi - eta_lo > eta_tol:\n",
    "        eta_mid = (eta_lo + eta_hi) / 2\n",
    "        eta_param.value = eta_mid\n",
    "        _, status = try_solve()\n",
    "        n_iter += 1\n",
    "        \n",
    "        if status in ('optimal', 'optimal_inaccurate'):\n",
    "            eta_hi = eta_mid\n",
    "            best_y = y.value.copy()\n",
    "            if verbose:\n",
    "                print(f\"    iter {n_iter}: eta={eta_mid:.8f} FEASIBLE\")\n",
    "        else:\n",
    "            eta_lo = eta_mid\n",
    "            if verbose:\n",
    "                print(f\"    iter {n_iter}: eta={eta_mid:.8f} infeasible ({status})\")\n",
    "    \n",
    "    solve_time = time.time() - t0\n",
    "    print(f\"  Binary search: {n_iter} iters, eta* in [{eta_lo:.8f}, {eta_hi:.8f}]\")\n",
    "    \n",
    "    result = {\n",
    "        'status': 'optimal', 'time': solve_time,\n",
    "        'solver': used_solver, 'd': d, 'n_moments': n_mom,\n",
    "        'bound': eta_hi, 'n_iter': n_iter,\n",
    "    }\n",
    "    \n",
    "    if best_y is not None:\n",
    "        first_mom = np.array([best_y[moment_idx[(i,)]] for i in range(P)])\n",
    "        Y_mat = np.zeros((P, P))\n",
    "        for i in range(P):\n",
    "            for j in range(P):\n",
    "                Y_mat[i, j] = best_y[moment_idx[tuple(sorted((i, j)))]]\n",
    "        M_val = sum(best_y[idx] * mat for idx, mat in B_M.items())\n",
    "        M_eigvals = np.linalg.eigvalsh(M_val)\n",
    "        M_rank = int(np.sum(M_eigvals > 1e-6 * max(M_eigvals.max(), 1e-12)))\n",
    "        result.update({\n",
    "            'first_moments': first_mom, 'Y': Y_mat,\n",
    "            'M': M_val, 'M_rank': M_rank, 'M_eigvals': M_eigvals,\n",
    "        })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 4: Primal solver for comparison.\"\"\"\n",
    "\n",
    "def solve_primal(P, n_restarts=20, seed=42):\n",
    "    \"\"\"Primal upper bound via softmax + L-BFGS-B with random restarts.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def softmax(z):\n",
    "        z = z - np.max(z)\n",
    "        e = np.exp(z)\n",
    "        return e / np.sum(e)\n",
    "    \n",
    "    def objective(z):\n",
    "        x = softmax(z)\n",
    "        conv = np.convolve(x, x, mode='full')\n",
    "        return 2 * P * np.max(conv)\n",
    "    \n",
    "    best_val = np.inf\n",
    "    best_x = None\n",
    "    for _ in range(n_restarts):\n",
    "        z0 = rng.randn(P) * 0.5\n",
    "        res = minimize(objective, z0, method='L-BFGS-B',\n",
    "                       options={'maxiter': 2000, 'ftol': 1e-15, 'gtol': 1e-10})\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = softmax(res.x)\n",
    "    \n",
    "    # Validate with exact computation\n",
    "    w = 1.0 / (2 * P)\n",
    "    edges = np.linspace(-0.25, 0.25, P + 1)\n",
    "    heights = best_x / w\n",
    "    sf = StepFunction(edges=edges, heights=heights)\n",
    "    val_exact = peak_autoconv_exact(sf)\n",
    "    return val_exact, best_x\n",
    "\n",
    "\n",
    "# Quick test\n",
    "v, x = solve_primal(4, n_restarts=10)\n",
    "print(f\"P=4 primal: {v:.6f}, x={np.round(x, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18838688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 5: Run for P = 2, 3, 4, 5, 6. Print comparison table.\"\"\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for P in [2, 3, 4, 5, 6]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"P = {P}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Lasserre level-2 (corrected: proper localizing matrices)\n",
    "    res = solve_lasserre_2(P)\n",
    "    \n",
    "    if res['bound'] is None:\n",
    "        print(f\"  Lasserre-2 FAILED ({res['status']})\")\n",
    "        continue\n",
    "    \n",
    "    # Primal\n",
    "    primal_val, x_primal = solve_primal(P, n_restarts=20)\n",
    "    \n",
    "    # Shor bound (= 2P/(2P-1))\n",
    "    shor = 2 * P / (2 * P - 1)\n",
    "    gap = primal_val - res['bound']\n",
    "    improvement_over_shor = res['bound'] - shor\n",
    "    gap_closed = improvement_over_shor / (primal_val - shor) * 100 if primal_val > shor else 0\n",
    "    \n",
    "    results.append({\n",
    "        'P': P,\n",
    "        'lasserre2': res['bound'],\n",
    "        'shor': shor,\n",
    "        'primal': primal_val,\n",
    "        'gap': gap,\n",
    "        'improvement': improvement_over_shor,\n",
    "        'gap_closed_pct': gap_closed,\n",
    "        'M_rank': res.get('M_rank', '?'),\n",
    "        'time': res['time'],\n",
    "        'status': res['status'],\n",
    "        'd': res['d'],\n",
    "        'n_iter': res.get('n_iter', 0),\n",
    "        'first_moments': res.get('first_moments'),\n",
    "    })\n",
    "    \n",
    "    print(f\"  Lasserre-2 LB: {res['bound']:.6f}\")\n",
    "    print(f\"  Shor LB:       {shor:.6f}\")\n",
    "    print(f\"  Improvement:   {improvement_over_shor:+.6f}\")\n",
    "    print(f\"  Primal UB:     {primal_val:.6f}\")\n",
    "    print(f\"  Remaining gap: {gap:.6f}\")\n",
    "    print(f\"  Gap closed:    {gap_closed:.1f}%\")\n",
    "    print(f\"  Rank(M):       {res.get('M_rank', '?')}\")\n",
    "    print(f\"  Wall time:     {res['time']:.1f}s ({res.get('n_iter',0)} bisection iters)\")\n",
    "    if res.get('first_moments') is not None:\n",
    "        print(f\"  y (1st mom):   {np.round(res['first_moments'], 4)}\")\n",
    "\n",
    "# Summary table\n",
    "print(f\"\\n{'='*105}\")\n",
    "print(f\"{'P':>3} | {'Lass-2 LB':>10} | {'Shor LB':>10} | {'Improv':>8} | {'Primal UB':>10} | \"\n",
    "      f\"{'Gap':>8} | {'Closed':>7} | {'Rank(M)':>7} | {'d':>4}\")\n",
    "print(f\"{'-'*105}\")\n",
    "for r in results:\n",
    "    print(f\"{r['P']:>3} | {r['lasserre2']:>10.6f} | {r['shor']:>10.6f} | \"\n",
    "          f\"{r['improvement']:>+8.4f} | {r['primal']:>10.6f} | {r['gap']:>8.4f} | \"\n",
    "          f\"{r['gap_closed_pct']:>6.1f}% | {r['M_rank']:>7} | {r['d']:>4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 6: Results plot and analysis.\"\"\"\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"No results to plot.\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    \n",
    "    Ps = [r['P'] for r in results]\n",
    "    lass2 = [r['lasserre2'] for r in results]\n",
    "    shors = [r['shor'] for r in results]\n",
    "    primals = [r['primal'] for r in results]\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(Ps, lass2, 'go-', label='Lasserre-2 LB', markersize=8, linewidth=2)\n",
    "    ax.plot(Ps, shors, 'b^--', label='Shor LB ($2P/(2P{-}1)$)', markersize=8)\n",
    "    ax.plot(Ps, primals, 'rs-', label='Primal UB', markersize=8)\n",
    "    ax.axhline(y=1.5029, color='gray', linestyle=':', alpha=0.7,\n",
    "               label='Best known $C_{1a} \\\\leq 1.5029$')\n",
    "    ax.set_xlabel('P (number of bins)')\n",
    "    ax.set_ylabel('Bound')\n",
    "    ax.set_title('Lasserre Level-2 vs Shor vs Primal')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    # Show improvement: Lasserre-2 minus Shor\n",
    "    improvements = [l - s for l, s in zip(lass2, shors)]\n",
    "    ax.bar(Ps, improvements, color='green', alpha=0.7)\n",
    "    ax.set_xlabel('P')\n",
    "    ax.set_ylabel('Lasserre-2 $-$ Shor')\n",
    "    ax.set_title('Improvement of Lasserre-2 over Shor')\n",
    "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lasserre_level2_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== Lasserre-2 vs Shor comparison ===\\n\")\n",
    "    for r in results:\n",
    "        improv = r['lasserre2'] - r['shor']\n",
    "        print(f\"P={r['P']}: Lasserre-2={r['lasserre2']:.8f}, \"\n",
    "              f\"Shor={r['shor']:.8f}, improvement={improv:+.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6sg417f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cell 7: Diagnostic -- check moment matrix rank and flatness.\"\"\"\n",
    "\n",
    "# If the moment matrix has low rank (especially rank 1), the relaxation is tight\n",
    "# and the optimal x can be extracted. Higher rank indicates remaining slack.\n",
    "\n",
    "for r in results:\n",
    "    P = r['P']\n",
    "    print(f\"\\n--- P = {P} ---\")\n",
    "    print(f\"  Lasserre-2 LB = {r['lasserre2']:.8f}\")\n",
    "    print(f\"  Shor LB       = {r['shor']:.8f}\")\n",
    "    print(f\"  Primal UB     = {r['primal']:.8f}\")\n",
    "    print(f\"  M_2 rank      = {r['M_rank']} (out of d={r['d']})\")\n",
    "    if r.get('first_moments') is not None:\n",
    "        x = r['first_moments']\n",
    "        print(f\"  E[x]          = {np.round(x, 5)}\")\n",
    "        print(f\"  sum(E[x])     = {np.sum(x):.8f}\")\n",
    "        # Check if first moments correspond to a good primal candidate\n",
    "        conv = np.convolve(x, x, mode='full')\n",
    "        primal_from_moments = 2 * P * np.max(conv)\n",
    "        print(f\"  Primal from E[x]: {primal_from_moments:.6f}\")\n",
    "    if r['M_rank'] == 1:\n",
    "        print(f\"  >>> TIGHT: rank-1 solution, relaxation is exact!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ysofsj97f",
   "metadata": {},
   "source": [
    "## Formulation Notes\n",
    "\n",
    "### Why localizing matrices matter for the epigraph constraints\n",
    "\n",
    "The discretized $C_{1a}$ problem is a **minimax** optimization:\n",
    "$$\\min_{x \\in \\Delta} \\max_k \\; 2P \\sum_{i+j=k} x_i x_j$$\n",
    "\n",
    "The epigraph reformulation introduces $\\eta$:\n",
    "$$\\min \\eta \\quad \\text{s.t.} \\quad \\eta - p_k(x) \\geq 0 \\;\\;\\forall k, \\quad x \\in \\Delta$$\n",
    "\n",
    "In the Lasserre hierarchy, each constraint $g(x) \\geq 0$ is enforced via a **localizing matrix**\n",
    "$M_{d-\\lceil \\deg g / 2\\rceil}(g \\cdot \\mu) \\succeq 0$, not merely the scalar $\\mathbb{E}[g(x)] \\geq 0$.\n",
    "\n",
    "For $g_k = \\eta - p_k(x)$ (degree 2), the level-2 localizing matrix is $M_1(g_k \\cdot \\mu)$,\n",
    "a $(P{+}1) \\times (P{+}1)$ PSD constraint with entries involving moments up to degree 4.\n",
    "This enforces $\\eta \\geq p_k(x)$ **pointwise on the support**, not just in expectation.\n",
    "\n",
    "Using only scalar constraints $\\eta \\geq \\mathbb{E}[p_k]$ reduces to the Shor relaxation,\n",
    "because distributions can equalize $\\mathbb{E}[p_k]$ by spreading mass -- but the localizing\n",
    "matrix prevents this by requiring $p_k(x) \\leq \\eta$ everywhere.\n",
    "\n",
    "### Bilinear structure and binary search\n",
    "\n",
    "The localizing matrix $\\eta \\cdot M_1(\\mu) - M_1(p_k \\cdot \\mu) \\succeq 0$ is bilinear in\n",
    "$(\\eta, y)$, so we cannot optimize $\\eta$ directly in a single SDP. Instead, we fix $\\eta$\n",
    "and solve a feasibility SDP, then binary search on $\\eta$.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "- If the Lasserre-2 bound significantly exceeds Shor, try larger $P$ to see scaling.\n",
    "- If the bound approaches the primal value, the relaxation may be tight or near-tight.\n",
    "- A rank-1 moment matrix certifies exact tightness and yields the optimal $x$.\n",
    "- Level-3 Lasserre would use $M_2$ localizing matrices for $g_k$, at higher computational cost."
   ]
  }
 ]
}